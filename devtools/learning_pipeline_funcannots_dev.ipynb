{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "from iotools.readOxford import ReadOxford\n",
    "from iotools.readrpkm import ReadRPKM\n",
    "from iotools.io_model import WriteModel\n",
    "from inference.linreg_association import LinRegAssociation\n",
    "from inference.empirical_bayes import EmpiricalBayes\n",
    "from utils import hyperparameters\n",
    "from inference import logmarglik\n",
    "from iotools import readgtf\n",
    "from utils import gtutils\n",
    "from utils import mfunc\n",
    "from utils.containers import ZstateInfo\n",
    "from utils.printstamp import printStamp\n",
    "from utils.helper_functions import write_params, load_target_genes\n",
    "from sklearn.preprocessing import scale\n",
    "from iotools import snp_annotator\n",
    "\n",
    "import config_dev as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotation (use complete gene name in gtf without trimming the version)\n",
    "# load annotation for whole genome\n",
    "gene_info = readgtf.gencode_v12(config.gtfpath, trim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 641 genes with high r2 values\n",
      "\n",
      "Found 57 genes in CHR 12\n",
      "['ENSG00000151065.9', 'ENSG00000078237.4', 'ENSG00000139194.3', 'ENSG00000173262.7', 'ENSG00000171860.4', 'ENSG00000205846.3', 'ENSG00000166527.3', 'ENSG00000256660.1', 'ENSG00000172243.13', 'ENSG00000139112.6', 'ENSG00000013583.4', 'ENSG00000123104.7', 'ENSG00000064115.6', 'ENSG00000139117.9', 'ENSG00000139174.6', 'ENSG00000161800.8', 'ENSG00000139610.1', 'ENSG00000167612.8', 'ENSG00000123395.10', 'ENSG00000170486.6', 'ENSG00000185640.5', 'ENSG00000135476.7', 'ENSG00000161638.6', 'ENSG00000123338.8', 'ENSG00000170473.12', 'ENSG00000135452.5', 'ENSG00000135655.9', 'ENSG00000183735.5', 'ENSG00000111554.10', 'ENSG00000090382.2', 'ENSG00000127337.2', 'ENSG00000135643.4', 'ENSG00000111615.8', 'ENSG00000139323.9', 'ENSG00000184752.8', 'ENSG00000139343.6', 'ENSG00000111145.3', 'ENSG00000136048.9', 'ENSG00000120860.6', 'ENSG00000136052.5', 'ENSG00000151131.5', 'ENSG00000136051.9', 'ENSG00000166046.6', 'ENSG00000110851.7', 'ENSG00000136003.11', 'ENSG00000110921.7', 'ENSG00000111199.6', 'ENSG00000176871.4', 'ENSG00000176834.9', 'ENSG00000170855.3', 'ENSG00000110917.3', 'ENSG00000182500.7', 'ENSG00000183955.8', 'ENSG00000139370.6', 'ENSG00000151948.7', 'ENSG00000111450.9', 'ENSG00000184967.2']\n"
     ]
    }
   ],
   "source": [
    "# Load gene list\n",
    "genelistfile = \"genes4testing_high_and_low_r2_0.001\"\n",
    "# genelistfile = \"genes4testing_highr2\"\n",
    "selected_gene_ids = load_target_genes(genelistfile, gene_info, config.chrom)\n",
    "print(selected_gene_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-16 01:28:09 - Reading pickled genotype\n",
      "2018-05-16 01:28:31 - Done reading\n",
      "2018-05-16 01:28:38 - Selection of samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not os.path.exists(config.learn_pickfile_dev):\n",
    "    # read Genotype\n",
    "    oxf = ReadOxford(config.gtex_gtpath, config.gtex_samplepath, config.chrom, config.learning_dataset)\n",
    "    genotype = np.array(oxf.dosage)\n",
    "    samplenames = oxf.samplenames\n",
    "    snps = oxf.snps_info\n",
    "\n",
    "    printStamp(\"Dumping CHR {:d} genotype\".format(config.chrom))\n",
    "    with open(config.learn_pickfile_dev, 'wb') as output:\n",
    "        pickle.dump(oxf, output, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    printStamp(\"Reading pickled genotype\")\n",
    "    with open(config.learn_pickfile_dev, 'rb') as input:\n",
    "        pickled_oxf = pickle.load(input)\n",
    "\n",
    "    printStamp(\"Done reading\")\n",
    "\n",
    "    genotype = np.array(pickled_oxf.dosage)\n",
    "    samplenames = pickled_oxf.samplenames\n",
    "    snps = pickled_oxf.snps_info\n",
    "    nsample = len(pickled_oxf.samplenames)\n",
    "\n",
    "# Quality control\n",
    "f_snps, f_genotype = gtutils.remove_low_maf(snps, genotype, 0.1)\n",
    "gt = gtutils.normalize(f_snps, f_genotype)\n",
    "\n",
    "# Gene Expression\n",
    "rpkm = ReadRPKM(config.gtex_rpkmpath, \"gtex\")\n",
    "expression = rpkm.expression\n",
    "expr_donors = rpkm.donor_ids\n",
    "gene_names = rpkm.gene_names\n",
    "\n",
    "# Selection\n",
    "printStamp(\"Selection of samples\")\n",
    "vcfmask, exprmask = mfunc.select_donors(samplenames, expr_donors)\n",
    "genes, indices = mfunc.select_genes(gene_info, gene_names)\n",
    "\n",
    "gene_training_list = []\n",
    "for i, gene in enumerate(genes):\n",
    "    k = indices[i]\n",
    "    if gene.ensembl_id in selected_gene_ids and gene.chrom == config.chrom:\n",
    "        gene_training_list.append((k,gene))\n",
    "        # print(k,gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gxpred-bslmm', [0.9, 0.0, 0.1, 0.1, 0.005], [None, None, None, None, None], None, 'test_1KGannots', 'soft', 'nodist', '1kg']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p = config.parameters[0]\n",
    "\n",
    "prior = p[0]\n",
    "params = p[1]\n",
    "hyperpriors = []\n",
    "hyperparams = p[3]\n",
    "run_description = p[4]\n",
    "cutoff = p[5]\n",
    "usedist = p[6]\n",
    "usefeat = p[7]\n",
    "\n",
    "print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/franco/soedinglab/dev_gxpred_models/z1/test_1KGannots/gxpred-bslmm_soft_nodist_1kg_0.900_0.000_0.100_0.100_0.005\n",
      "/home/franco/cluster2/datasets/1KG_annots/1KG.12.annot.gz\n",
      "14210 GeneInfo(name='RACGAP1', ensembl_id='ENSG00000161800.8', chrom=12, start=50370706, end=50426918)\n",
      "2018-05-16 01:31:09 - Learning for gene ENSG00000161800.8\n",
      "Found 1929 SNPs, reduced to 200 SNPs (max p-value 0.137009) for RACGAP1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-cafbcac50940>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature1kg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# add UTR feature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "from iotools import snp_annotator\n",
    "from collections import defaultdict\n",
    "import gzip \n",
    "\n",
    "model_dir = \"{:s}_{:s}_{:s}_{:s}_{:.3f}_{:.3f}_{:.3f}_{:.3f}_{:.3f}\".format(prior, cutoff, usedist, usefeat, params[0], params[1], params[2], params[3], params[4])\n",
    "outdir = \"/home/franco/soedinglab/dev_gxpred_models/\"\n",
    "modelpath = os.path.join(outdir, \"z\"+str(config.zmax), config.run_description, model_dir)\n",
    "\n",
    "print(modelpath)\n",
    "\n",
    "write_params(modelpath, p)\n",
    "\n",
    "model = WriteModel(modelpath, config.chrom)\n",
    "\n",
    "# Load rsid dictionary\n",
    "annot_dict = defaultdict(list)\n",
    "if usefeat == \"1kg\":\n",
    "    annotfile = os.path.join(config.annot1kg_dir, \"1KG.\"+str(config.chrom)+\".annot.gz\")\n",
    "    print(annotfile)\n",
    "    with gzip.open(annotfile, 'r') as instream:\n",
    "        _ = instream.readline()\n",
    "        for line in instream:\n",
    "            arr = line.decode().strip().split(\" \")\n",
    "            rsid = arr[0]\n",
    "            annots = list(map(int, arr[1:]))\n",
    "            annot_dict[rsid] = annots\n",
    "\n",
    "\n",
    "# for i in range(0,len(gene_training_list)):\n",
    "for i in range(15,20):\n",
    "\n",
    "    k, gene = gene_training_list[i]\n",
    "\n",
    "    print(k, gene)\n",
    "\n",
    "    printStamp(\"Learning for gene \"+str(gene.ensembl_id))\n",
    "\n",
    "    # select only the cis-SNPs\n",
    "    cismask = mfunc.select_snps(gene, f_snps, config.window)\n",
    "    if len(cismask) > 0:\n",
    "        target = expression[k, exprmask]\n",
    "        target = scale(target, with_mean=True, with_std=True)\n",
    "        predictor = gt[cismask][:, vcfmask]\n",
    "        snpmask = cismask\n",
    "\n",
    "        # if number of cis SNPs > threshold, use p-value cut-off\n",
    "\n",
    "        min_pos = f_snps[cismask[0]].bp_pos - 1000\n",
    "        max_pos = f_snps[cismask[-1]].bp_pos + 1000\n",
    "        \n",
    "        if len(cismask) > config.min_snps:\n",
    "            assoc_model = LinRegAssociation(predictor, target, config.min_snps, config.pval_cutoff, cutoff)\n",
    "            pvalmask = cismask[assoc_model.selected_variables]\n",
    "            if pvalmask.shape[0] == 0:\n",
    "                print(\"No significant SNPs found for gene {:s}\".format(gene.ensembl_id))\n",
    "                continue\n",
    "            print (\"Found {:d} SNPs, reduced to {:d} SNPs (max p-value {:g}) for {:s}\".format(len(cismask), len(pvalmask), assoc_model.ordered_pvals[len(pvalmask) - 1], gene.name))\n",
    "            predictor = gt[pvalmask][:, vcfmask]\n",
    "            snpmask = pvalmask\n",
    "        else:\n",
    "            print (\"Found {:d} SNPs for {:s}\".format(len(cismask), gene.name))\n",
    "\n",
    "        if config.shuffle_geno:\n",
    "            print(\"Shuffling Genotype!\")\n",
    "            np.random.shuffle(predictor.T)\n",
    "\n",
    "        selected_snps = [f_snps[x] for x in snpmask]\n",
    "\n",
    "        if config.prune_LD:\n",
    "            ld_indices = snp_annotator.get_snps_LD(gene, selected_snps, min_pos, max_pos, config.genofile_plink, config.ldstorepath, config.ld_path)\n",
    "            snpmask = np.delete(snpmask, np.reshape(ld_indices, -1))\n",
    "            predictor = gt[snpmask][:, vcfmask]\n",
    "\n",
    "            # replace with the pruned snsp in LD\n",
    "            selected_snps = [f_snps[x] for x in snpmask]\n",
    "\n",
    "            print (\"Reduced to {:d} SNPs\".format(len(snpmask)))\n",
    "        \n",
    "        # read the features\n",
    "        # TODO: only returns the base feature (vect of 1's)\n",
    "        feature0 = np.ones((len(selected_snps), 1))\n",
    "        \n",
    "        if usefeat == \"1kg\":\n",
    "            current_annot = list()\n",
    "            for snp in selected_snps:\n",
    "                if len(annot_dict[snp.varid]) > 0:\n",
    "                    current_annot.append(annot_dict[snp.varid])\n",
    "                else:\n",
    "                    current_annot.append([0,0,0,0,0])\n",
    "                    print(\"not found {:s}!\".format(snp.varid))\n",
    "            feature1kg = np.array(current_annot)\n",
    "        \n",
    "        features = np.concatenate((feature0, feature1kg), axis=1)\n",
    "        raise\n",
    "                    \n",
    "        # add UTR feature\n",
    "#         utr_feature = snp_annotator.get_GENCODE_annotation(config.gtfpath, gene, selected_snps, \"UTR\")\n",
    "#         exon_feature = snp_annotator.get_GENCODE_annotation(config.gtfpath, gene, selected_snps, \"exon\")\n",
    "#         features = np.concatenate((feature0, utr_feature, exon_feature), axis=1)\n",
    "\n",
    "        # Get DHS distance feature\n",
    "        dist_feature = snp_annotator.get_distance_feature(selected_snps, gene, usedist)\n",
    "\n",
    "        nfeat = features.shape[1]\n",
    "        print(\"Loaded {:d} features\".format(nfeat))\n",
    "\n",
    "        init_params = np.zeros(nfeat + 4)\n",
    "        init_params[0] = - np.log((1 / params[0]) - 1)\n",
    "        if nfeat > 1:\n",
    "            for i in range(1, nfeat):\n",
    "                init_params[i] = - np.log((1 / params[0]) - 1)\n",
    "        init_params[nfeat + 0] = params[1] # mu\n",
    "        init_params[nfeat + 1] = params[2] # sigma\n",
    "        init_params[nfeat + 2] = params[3] # sigmabg\n",
    "        init_params[nfeat + 3] = 1 / params[4] / params[4] # tau\n",
    "\n",
    "        # perform the analysis\n",
    "\n",
    "        print (\"Starting first optimization ==============\")\n",
    "        emp_bayes = EmpiricalBayes(predictor, target, features, dist_feature, 1, init_params, method=\"new\")\n",
    "        emp_bayes.fit()\n",
    "        if config.zmax > 1:\n",
    "            if emp_bayes.success:\n",
    "                res = emp_bayes.params\n",
    "                print (\"Starting second optimization from previous results ================\")\n",
    "                # Python Error: C library could not compute z-components. Check C errors above.\n",
    "            else:\n",
    "                res = init_params\n",
    "                print (\"Starting second optimization from initial parameters ================\")\n",
    "            emp_bayes = EmpiricalBayes(predictor, target, features, dist_feature, config.zmax, res, method=\"new\")\n",
    "            emp_bayes.fit()\n",
    "\n",
    "        if emp_bayes.success:\n",
    "            res = emp_bayes.params\n",
    "            res[4] = 1 / np.sqrt(res[4])\n",
    "\n",
    "            print(res)\n",
    "#             print(\"PI: \\t\",res[0])\n",
    "#             print(\"mu: \\t\",res[1])\n",
    "#             print(\"sigma: \\t\",res[2])\n",
    "#             print(\"sigmabg: \\t\",res[3])\n",
    "#             print(\"tau: \\t\",res[4])\n",
    "\n",
    "            model_snps = [f_snps[x] for x in snpmask]\n",
    "            model_zstates = list()\n",
    "            scaledparams = hyperparameters.scale(emp_bayes.params)\n",
    "            zprob, zexp = logmarglik.model_exp(scaledparams, predictor, target, features, dist_feature, emp_bayes.zstates)\n",
    "            for j, z in enumerate(emp_bayes.zstates):\n",
    "                this_zstate = ZstateInfo(state = z,\n",
    "                                         prob  = zprob[j],\n",
    "                                         exp   = list(zexp[j, :]) )\n",
    "                model_zstates.append(this_zstate)\n",
    "            # print(model_snps)\n",
    "            # for i,m in enumerate(model_zstates):\n",
    "            #     print(\"z-state: \",i,\" Prob:\", m.prob)\n",
    "            model.write_success_gene(gene, model_snps, model_zstates, res)\n",
    "        else:\n",
    "            model.write_failed_gene(gene, np.zeros_like(init_params))\n",
    "            print (\"Failed optimization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([200.,   3.,  10.,  25.,  50., 103.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(features, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "import pickle\n",
    "from utils.printstamp import printStamp\n",
    "from iotools.io_model import ReadModel\n",
    "from iotools.readOxford import ReadOxford\n",
    "from utils.containers import GeneExpressionArray\n",
    "from utils import gtutils\n",
    "from utils import mfunc\n",
    "import numpy as np\n",
    "import config_dev as config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-14 21:53:11 - Reading pickled genotype\n",
      "2018-05-14 21:54:04 - Done reading\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not os.path.exists(config.p_pickfile_dev):\n",
    "# Read genotype (quite slow for testing) use pickle below\n",
    "    p_oxf = ReadOxford(config.p_gtpath, config.p_samplepath, config.chrom, config.predicting_dataset)\n",
    "    p_genotype = np.array(p_oxf.dosage)\n",
    "    p_samplenames = p_oxf.samplenames\n",
    "    p_snps = p_oxf.snps_info\n",
    "    p_nsample = len(p_oxf.samplenames)\n",
    "\n",
    "    printStamp(\"Dumping CHR {:d} genotype\".format(chrom))\n",
    "    with open(config.p_pickfile_dev, 'wb') as output:\n",
    "        pickle.dump(p_oxf, output, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    printStamp(\"Reading pickled genotype\")\n",
    "    with open(config.p_pickfile_dev, 'rb') as input:\n",
    "        pickled_oxf = pickle.load(input)\n",
    "\n",
    "    printStamp(\"Done reading\")\n",
    "\n",
    "    p_genotype = np.array(pickled_oxf.dosage)\n",
    "    p_samplenames = pickled_oxf.samplenames\n",
    "    p_snps = pickled_oxf.snps_info\n",
    "    p_nsample = len(pickled_oxf.samplenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gxpred-bslmm', [0.9, 0.0, 0.1, 0.1, 0.005], [None, None, None, None, None], None, 'test_1KGannots', 'soft', 'nodist', '1kg']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p = config.parameters[0]\n",
    "\n",
    "prior = p[0]\n",
    "params = p[1]\n",
    "hyperpriors = []\n",
    "hyperparams = p[3]\n",
    "run_description = p[4]\n",
    "cutoff = p[5]\n",
    "usedist = p[6]\n",
    "usefeat = p[7]\n",
    "\n",
    "print(p)\n",
    "\n",
    "\n",
    "model_dir = \"{:s}_{:s}_{:s}_{:s}_{:.3f}_{:.3f}_{:.3f}_{:.3f}_{:.3f}\".format(prior, cutoff, usedist, usefeat, params[0], params[1], params[2], params[3], params[4])\n",
    "outdir = \"/home/franco/soedinglab/dev_gxpred_models/\"\n",
    "modelpath = os.path.join(outdir, \"z\"+str(config.zmax), config.run_description, model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-05-14 21:56:06 - Predicting for /home/franco/soedinglab/dev_gxpred_models/z1/test_1KGannots/gxpred-bslmm_newsoft_nodist_1kg_0.900_0.000_0.100_0.100_0.005\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "File /home/franco/soedinglab/dev_gxpred_models/z1/test_1KGannots/gxpred-bslmm_newsoft_nodist_1kg_0.900_0.000_0.100_0.100_0.005/chr12/genes.txt does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-5b545234ba10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Write predictions for each model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mp_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReadModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchrom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mp_genes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mgx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgene\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp_genes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cluster2/gxpred_annots/gxpred/iotools/io_model.py\u001b[0m in \u001b[0;36mgenes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_genes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_genefilename\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\" does not exist\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_genes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: File /home/franco/soedinglab/dev_gxpred_models/z1/test_1KGannots/gxpred-bslmm_newsoft_nodist_1kg_0.900_0.000_0.100_0.100_0.005/chr12/genes.txt does not exist"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "outfileprefix = os.path.join(modelpath,\"pred_chr\"+str(config.chrom))\n",
    "\n",
    "printStamp(\"Predicting for \"+modelpath)\n",
    "# Write predictions for each model\n",
    "p_model = ReadModel(modelpath, config.chrom)\n",
    "p_genes = p_model.genes\n",
    "gx = list()\n",
    "for gene in p_genes:\n",
    "\n",
    "    p_model.read_gene(gene)\n",
    "    p_model_snps = p_model.snps\n",
    "    p_model_zstates = p_model.zstates\n",
    "\n",
    "    x = gtutils.prediction_variables(p_snps, p_model_snps, p_genotype)\n",
    "    x = gtutils.normalize(p_model_snps, x)\n",
    "\n",
    "    ypred = np.zeros(p_nsample)\n",
    "    for z in p_model_zstates:\n",
    "        ypred += z.prob * np.dot(x.T, z.exp)\n",
    "\n",
    "    gx.append(GeneExpressionArray(geneid = gene.ensembl_id, expr_arr = ypred))\n",
    "\n",
    "\n",
    "# Write output\n",
    "printStamp(\"Done predicting for \"+modelpath)\n",
    "mfunc.write_gcta_phenotype(outfileprefix, p_samplenames, gx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "from iotools import readgtf\n",
    "from iotools.readrpkm import ReadRPKM\n",
    "from iotools.readPrediction import ReadPrediction\n",
    "from scipy.stats import pearsonr\n",
    "from utils.helper_functions import write_r2_dataframe, get_common_elements, pearson_corr_rowwise\n",
    "import math\n",
    "import pickle\n",
    "from utils.printstamp import printStamp\n",
    "\n",
    "import config_dev as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load reference dataset Gene Expression\n",
    "reference_rpkm = ReadRPKM(config.reference_expdatapath, config.predicting_dataset)\n",
    "reference_expression = reference_rpkm.expression\n",
    "reference_expr_donors = reference_rpkm.donor_ids\n",
    "reference_gene_names = reference_rpkm.gene_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the selected_gene_ids with high R² values as targets, only those in the selected chrom will appear\n",
    "# genelistfile = \"genes4testing_highr2\"\n",
    "genelistfile = \"genes4testing_high_and_low_r2_0.001\"\n",
    "selected_gene_ids = load_target_genes(genelistfile, gene_info, config.chrom)\n",
    "target_genelist = [g.split(\".\")[0] for g in selected_gene_ids]\n",
    "target_donors = reference_expr_donors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Predixcan assessment ###\n",
    "\n",
    "if not os.path.exists(config.predixcan_pickfile_dev):\n",
    "    predixcanpred = ReadPrediction(config.pxpred_predpath, config.reference_samplepath, \"predixcan\", trim=True)\n",
    "\n",
    "    if len(predixcanpred.gene_names) > 0:\n",
    "        printStamp(\"Dumping Predixcan prediction\")\n",
    "        with open(config.predixcan_pickfile_dev, 'wb') as output:\n",
    "            pickle.dump(predixcanpred, output, pickle.HIGHEST_PROTOCOL)\n",
    "    else:\n",
    "        raise(\"No prediction data found\")\n",
    "else:\n",
    "    printStamp(\"Reading pickled Predixcan prediction\")\n",
    "    with open(config.predixcan_pickfile_dev, 'rb') as input:\n",
    "        predixcanpred = pickle.load(input)\n",
    "\n",
    "# filter predixcan predictions with only those in gxpred\n",
    "predixcanpred.sort_by_gene(target_genelist)\n",
    "predixcanpred.sort_by_samples(target_donors, use_prev=True)\n",
    "\n",
    "sorted_expr_donors, ix_samples = get_common_elements(reference_expr_donors, predixcanpred.sorted_samples)\n",
    "sorted_gene_names, ix_genes = get_common_elements(reference_gene_names, predixcanpred.sorted_gene_names)\n",
    "sorted_expression = reference_expression[ix_genes,:][:, ix_samples].T\n",
    "\n",
    "predixcan_r = pearson_corr_rowwise(predixcanpred.sorted_expr_mat.T, sorted_expression.T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "### GXpred assessment ###\n",
    "\n",
    "print(modelpath)\n",
    "\n",
    "gxpred_predpath = os.path.join(modelpath)\n",
    "gxpred = ReadPrediction(gxpred_predpath, config.reference_samplepath, \"gxpred\", trim=True)\n",
    "\n",
    "# filter gxpred predicted values\n",
    "gxpred.sort_by_gene(target_genelist)\n",
    "gxpred.sort_by_samples(target_donors, use_prev=True)\n",
    "\n",
    "\n",
    "# Filter and sort the reference expression values\n",
    "# Cardiogenics variables\n",
    "# expression\n",
    "# expr_donors\n",
    "# gene_names\n",
    "\n",
    "sorted_expr_donors, ix_samples = get_common_elements(reference_expr_donors, gxpred.sorted_samples)\n",
    "sorted_gene_names, ix_genes = get_common_elements(reference_gene_names, gxpred.sorted_gene_names)\n",
    "sorted_expression = reference_expression[ix_genes,:][:, ix_samples].T\n",
    "\n",
    "# Calculate Pearson correlation\n",
    "gxpred_r = pearson_corr_rowwise(gxpred.sorted_expr_mat.T, sorted_expression.T)\n",
    "\n",
    "print(gxpred.sorted_gene_names)\n",
    "print(gxpred_r**2)\n",
    "print(predixcan_r**2)\n",
    "\n",
    "\n",
    "# Write to table with predictions for given genes\n",
    "# predtabledir = os.path.join(home, \"gxpred\",\"devtools\", \"all_predictions.txt\")\n",
    "# new_write_predicted_r2(predtabledir, prior, params, gxpred_r, predixcan_r, gxpred.sorted_gene_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "write_r2_dataframe(modelpath, config.chrom, \"predixcan\", predixcan_r, predixcanpred, overwrite=True)\n",
    "write_r2_dataframe(modelpath, config.chrom, \"gxpred-bslmm\", gxpred_r, gxpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
