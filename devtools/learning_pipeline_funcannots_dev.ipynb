{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import math\n",
    "import pickle\n",
    "from iotools.readOxford import ReadOxford\n",
    "from iotools.readrpkm import ReadRPKM\n",
    "from iotools.io_model import WriteModel\n",
    "from inference.linreg_association import LinRegAssociation\n",
    "from inference.empirical_bayes import EmpiricalBayes\n",
    "from utils import hyperparameters\n",
    "from inference import logmarglik\n",
    "from iotools import readgtf\n",
    "from utils import gtutils\n",
    "from utils import mfunc\n",
    "from utils.containers import ZstateInfo\n",
    "from utils.printstamp import printStamp\n",
    "from utils.helper_functions import write_params, load_target_genes\n",
    "from sklearn.preprocessing import scale\n",
    "from iotools import snp_annotator\n",
    "\n",
    "import config_annots as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Annotation (use complete gene name in gtf without trimming the version)\n",
    "# load annotation for whole genome\n",
    "gene_info = readgtf.gencode_v12(config.gtfpath, trim=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 641 genes with high r2 values\n",
      "\n",
      "Found 57 genes in CHR 12\n",
      "['ENSG00000151065.9', 'ENSG00000078237.4', 'ENSG00000139194.3', 'ENSG00000173262.7', 'ENSG00000171860.4', 'ENSG00000205846.3', 'ENSG00000166527.3', 'ENSG00000256660.1', 'ENSG00000172243.13', 'ENSG00000139112.6', 'ENSG00000013583.4', 'ENSG00000123104.7', 'ENSG00000064115.6', 'ENSG00000139117.9', 'ENSG00000139174.6', 'ENSG00000161800.8', 'ENSG00000139610.1', 'ENSG00000167612.8', 'ENSG00000123395.10', 'ENSG00000170486.6', 'ENSG00000185640.5', 'ENSG00000135476.7', 'ENSG00000161638.6', 'ENSG00000123338.8', 'ENSG00000170473.12', 'ENSG00000135452.5', 'ENSG00000135655.9', 'ENSG00000183735.5', 'ENSG00000111554.10', 'ENSG00000090382.2', 'ENSG00000127337.2', 'ENSG00000135643.4', 'ENSG00000111615.8', 'ENSG00000139323.9', 'ENSG00000184752.8', 'ENSG00000139343.6', 'ENSG00000111145.3', 'ENSG00000136048.9', 'ENSG00000120860.6', 'ENSG00000136052.5', 'ENSG00000151131.5', 'ENSG00000136051.9', 'ENSG00000166046.6', 'ENSG00000110851.7', 'ENSG00000136003.11', 'ENSG00000110921.7', 'ENSG00000111199.6', 'ENSG00000176871.4', 'ENSG00000176834.9', 'ENSG00000170855.3', 'ENSG00000110917.3', 'ENSG00000182500.7', 'ENSG00000183955.8', 'ENSG00000139370.6', 'ENSG00000151948.7', 'ENSG00000111450.9', 'ENSG00000184967.2']\n"
     ]
    }
   ],
   "source": [
    "# Load gene list\n",
    "genelistfile = \"genes4testing_high_and_low_r2_0.001\"\n",
    "# genelistfile = \"genes4testing_highr2\"\n",
    "selected_gene_ids = load_target_genes(genelistfile, gene_info, config.chrom)\n",
    "print(selected_gene_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-04-23 17:55:14 - Reading pickled genotype\n",
      "2018-04-23 17:55:18 - Done reading\n",
      "2018-04-23 17:55:25 - Selection of samples\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if not os.path.exists(config.learn_pickfile_dev):\n",
    "    # read Genotype\n",
    "    oxf = ReadOxford(config.gtex_gtpath, config.gtex_samplepath, config.chrom, config.learning_dataset)\n",
    "    genotype = np.array(oxf.dosage)\n",
    "    samplenames = oxf.samplenames\n",
    "    snps = oxf.snps_info\n",
    "\n",
    "    printStamp(\"Dumping CHR {:d} genotype\".format(config.chrom))\n",
    "    with open(config.learn_pickfile_dev, 'wb') as output:\n",
    "        pickle.dump(oxf, output, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    printStamp(\"Reading pickled genotype\")\n",
    "    with open(config.learn_pickfile_dev, 'rb') as input:\n",
    "        pickled_oxf = pickle.load(input)\n",
    "\n",
    "    printStamp(\"Done reading\")\n",
    "\n",
    "    genotype = np.array(pickled_oxf.dosage)\n",
    "    samplenames = pickled_oxf.samplenames\n",
    "    snps = pickled_oxf.snps_info\n",
    "    nsample = len(pickled_oxf.samplenames)\n",
    "\n",
    "# Quality control\n",
    "f_snps, f_genotype = gtutils.remove_low_maf(snps, genotype, 0.1)\n",
    "gt = gtutils.normalize(f_snps, f_genotype)\n",
    "\n",
    "# Gene Expression\n",
    "rpkm = ReadRPKM(config.gtex_rpkmpath, \"gtex\")\n",
    "expression = rpkm.expression\n",
    "expr_donors = rpkm.donor_ids\n",
    "gene_names = rpkm.gene_names\n",
    "\n",
    "# Selection\n",
    "printStamp(\"Selection of samples\")\n",
    "vcfmask, exprmask = mfunc.select_donors(samplenames, expr_donors)\n",
    "genes, indices = mfunc.select_genes(gene_info, gene_names)\n",
    "\n",
    "gene_training_list = []\n",
    "for i, gene in enumerate(genes):\n",
    "    k = indices[i]\n",
    "    if gene.ensembl_id in selected_gene_ids and gene.chrom == config.chrom:\n",
    "        gene_training_list.append((k,gene))\n",
    "        # print(k,gene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gxpred-bslmm', [0.1, 0.0, 0.1, 0.1, 0.005], [None, None, None, None, None], None, 'snp_annotator_dev2_utrexon_boundG0', 'newsoft', 'nodist', 'nofeat']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p = config.parameters[0]\n",
    "\n",
    "prior = p[0]\n",
    "params = p[1]\n",
    "hyperpriors = []\n",
    "hyperparams = p[3]\n",
    "run_description = p[4]\n",
    "cutoff = p[5]\n",
    "usedist = p[6]\n",
    "usefeat = p[7]\n",
    "\n",
    "print(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from iotools import snp_annotator\n",
    "\n",
    "model_dir = \"{:s}_{:s}_{:s}_{:s}_{:.3f}_{:.3f}_{:.3f}_{:.3f}_{:.3f}\".format(prior, cutoff, usedist, usefeat, params[0], params[1], params[2], params[3], params[4])\n",
    "outdir = \"/home/franco/soedinglab/dev_gxpred_models/\"\n",
    "modelpath = os.path.join(outdir, \"z\"+str(config.zmax), config.run_description, model_dir)\n",
    "\n",
    "print(modelpath)\n",
    "\n",
    "write_params(modelpath, p)\n",
    "\n",
    "model = WriteModel(modelpath, config.chrom)\n",
    "\n",
    "for i in range(0,len(gene_training_list)):\n",
    "# for i in range(4,5):\n",
    "\n",
    "    k, gene = gene_training_list[i]\n",
    "\n",
    "    print(k, gene)\n",
    "\n",
    "    printStamp(\"Learning for gene \"+str(gene.ensembl_id))\n",
    "\n",
    "    # select only the cis-SNPs\n",
    "    cismask = mfunc.select_snps(gene, f_snps, config.window)\n",
    "    if len(cismask) > 0:\n",
    "        target = expression[k, exprmask]\n",
    "        target = scale(target, with_mean=True, with_std=True)\n",
    "        predictor = gt[cismask][:, vcfmask]\n",
    "        snpmask = cismask\n",
    "\n",
    "        # if number of cis SNPs > threshold, use p-value cut-off\n",
    "\n",
    "        if len(cismask) > config.min_snps:\n",
    "            assoc_model = LinRegAssociation(predictor, target, config.min_snps, config.pval_cutoff, cutoff)\n",
    "            pvalmask = cismask[assoc_model.selected_variables]\n",
    "            if pvalmask.shape[0] == 0:\n",
    "                print(\"No significant SNPs found for gene {:s}\".format(gene.ensembl_id))\n",
    "                continue\n",
    "            print (\"Found {:d} SNPs, reduced to {:d} SNPs (max p-value {:g}) for {:s}\".format(len(cismask), len(pvalmask), assoc_model.ordered_pvals[len(pvalmask) - 1], gene.name))\n",
    "            predictor = gt[pvalmask][:, vcfmask]\n",
    "            snpmask = pvalmask\n",
    "        else:\n",
    "            print (\"Found {:d} SNPs for {:s}\".format(len(cismask), gene.name))\n",
    "\n",
    "        if config.shuffle_geno:\n",
    "            print(\"Shuffling Genotype!\")\n",
    "            np.random.shuffle(predictor.T)\n",
    "\n",
    "        selected_snps = [f_snps[x] for x in snpmask]\n",
    "\n",
    "        # read the features\n",
    "        # TODO: only returns the base feature (vect of 1's)\n",
    "        feature0 = np.ones((len(selected_snps), 1))\n",
    "\n",
    "        # add UTR feature\n",
    "        utr_feature = snp_annotator.get_GENCODE_annotation(config.gtfpath, gene, selected_snps, \"UTR\")\n",
    "        exon_feature = snp_annotator.get_GENCODE_annotation(config.gtfpath, gene, selected_snps, \"exon\")\n",
    "        features = np.concatenate((feature0, utr_feature, exon_feature), axis=1)\n",
    "\n",
    "        # Get DHS distance feature\n",
    "        dist_feature = snp_annotator.get_distance_feature(selected_snps, gene, usedist)\n",
    "\n",
    "        nfeat = features.shape[1]\n",
    "        print(\"Loaded {:d} features\".format(nfeat))\n",
    "\n",
    "        init_params = np.zeros(nfeat + 4)\n",
    "        init_params[0] = - np.log((1 / params[0]) - 1)\n",
    "        if nfeat > 1:\n",
    "            for i in range(1, nfeat):\n",
    "                init_params[i] = - np.log((1 / params[0]) - 1)\n",
    "        init_params[nfeat + 0] = params[1] # mu\n",
    "        init_params[nfeat + 1] = params[2] # sigma\n",
    "        init_params[nfeat + 2] = params[3] # sigmabg\n",
    "        init_params[nfeat + 3] = 1 / params[4] / params[4] # tau\n",
    "\n",
    "        # perform the analysis\n",
    "\n",
    "        print (\"Starting first optimization ==============\")\n",
    "        emp_bayes = EmpiricalBayes(predictor, target, features, dist_feature, 1, init_params, method=\"new\")\n",
    "        emp_bayes.fit()\n",
    "        if config.zmax > 1:\n",
    "            if emp_bayes.success:\n",
    "                res = emp_bayes.params\n",
    "                print (\"Starting second optimization from previous results ================\")\n",
    "                # Python Error: C library could not compute z-components. Check C errors above.\n",
    "            else:\n",
    "                res = init_params\n",
    "                print (\"Starting second optimization from initial parameters ================\")\n",
    "            emp_bayes = EmpiricalBayes(predictor, target, features, dist_feature, config.zmax, res, method=\"new\")\n",
    "            emp_bayes.fit()\n",
    "\n",
    "        if emp_bayes.success:\n",
    "            res = emp_bayes.params\n",
    "            res[4] = 1 / np.sqrt(res[4])\n",
    "\n",
    "            print(res)\n",
    "#             print(\"PI: \\t\",res[0])\n",
    "#             print(\"mu: \\t\",res[1])\n",
    "#             print(\"sigma: \\t\",res[2])\n",
    "#             print(\"sigmabg: \\t\",res[3])\n",
    "#             print(\"tau: \\t\",res[4])\n",
    "\n",
    "            model_snps = [f_snps[x] for x in snpmask]\n",
    "            model_zstates = list()\n",
    "            scaledparams = hyperparameters.scale(emp_bayes.params)\n",
    "            zprob, zexp = logmarglik.model_exp(scaledparams, predictor, target, features, dist_feature, emp_bayes.zstates)\n",
    "            for j, z in enumerate(emp_bayes.zstates):\n",
    "                this_zstate = ZstateInfo(state = z,\n",
    "                                         prob  = zprob[j],\n",
    "                                         exp   = list(zexp[j, :]) )\n",
    "                model_zstates.append(this_zstate)\n",
    "            # print(model_snps)\n",
    "            # for i,m in enumerate(model_zstates):\n",
    "            #     print(\"z-state: \",i,\" Prob:\", m.prob)\n",
    "            model.write_success_gene(gene, model_snps, model_zstates, res)\n",
    "        else:\n",
    "            model.write_failed_gene(gene, np.zeros_like(init_params))\n",
    "            print (\"Failed optimization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_start = gene.start - config.window\n",
    "w_end = gene.end + config.window\n",
    "print(w_start, w_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# developing get_gencode_data_for_gene()\n",
    "\n",
    "import gzip\n",
    "from utils.containers import GeneInfo\n",
    "annotfile = config.gtfpath\n",
    "feature = \"gene\"\n",
    "biotype=['protein_coding']\n",
    "trim=False\n",
    "geneinfo = list()\n",
    "with gzip.open(annotfile, 'r') as mfile:\n",
    "    for line in mfile:\n",
    "        linesplit = line.decode().strip().split('\\t')\n",
    "        \n",
    "        if linesplit[0][0] == '#' or linesplit[2] == 'gene': continue # skip header\n",
    "        chrom = linesplit[0][3:]\n",
    "        \n",
    "        infolist = linesplit[8].split(';')\n",
    "        rowtype = infolist[2].strip().split(' ')[1].replace('\"','')\n",
    "\n",
    "#         explore tags?\n",
    "#         for e in infolist:\n",
    "#             arr = e.strip().split(' ')\n",
    "#             if arr[0] == \"tag\":\n",
    "                \n",
    "\n",
    "\n",
    "        gene_id = infolist[0].strip().split(' ')[1].replace('\"','')\n",
    "        if trim:\n",
    "            gene_id = gene_id.split(\".\")[0]\n",
    "        if gene.ensembl_id != gene_id:\n",
    "            continue\n",
    "        if linesplit[2] != \"UTR\":\n",
    "            continue\n",
    "            \n",
    "        # TSS: gene start (0-based coordinates for BED)\n",
    "        if linesplit[6] == '+':\n",
    "            start = np.int64(linesplit[3]) - 1\n",
    "            end   = np.int64(linesplit[4])\n",
    "        elif linesplit[6] == '-':\n",
    "            start = np.int64(linesplit[3])  # last base of gene\n",
    "            end   = np.int64(linesplit[4]) - 1\n",
    "        else:\n",
    "            raise ValueError('Strand not specified.')\n",
    "        print(linesplit)\n",
    "        print(gene_id, linesplit[2])\n",
    "        print(rowtype)\n",
    "        \n",
    "        gene_name = infolist[4].strip().split(' ')[1].replace('\"','')\n",
    "        this_gene = GeneInfo(name       = \"UTR\",\n",
    "                             ensembl_id = gene_id,\n",
    "                             chrom      = int(chrom),\n",
    "                             start      = start,\n",
    "                             end        = end)\n",
    "\n",
    "        geneinfo.append(this_gene)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geneinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "import pickle\n",
    "from utils.printstamp import printStamp\n",
    "from iotools.io_model import ReadModel\n",
    "from iotools.readOxford import ReadOxford\n",
    "from utils.containers import GeneExpressionArray\n",
    "from utils import gtutils\n",
    "from utils import mfunc\n",
    "import numpy as np\n",
    "import config_annots as config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not os.path.exists(config.p_pickfile_dev):\n",
    "# Read genotype (quite slow for testing) use pickle below\n",
    "    p_oxf = ReadOxford(config.p_gtpath, config.p_samplepath, config.chrom, config.predicting_dataset)\n",
    "    p_genotype = np.array(p_oxf.dosage)\n",
    "    p_samplenames = p_oxf.samplenames\n",
    "    p_snps = p_oxf.snps_info\n",
    "    p_nsample = len(p_oxf.samplenames)\n",
    "\n",
    "    printStamp(\"Dumping CHR {:d} genotype\".format(chrom))\n",
    "    with open(config.p_pickfile_dev, 'wb') as output:\n",
    "        pickle.dump(p_oxf, output, pickle.HIGHEST_PROTOCOL)\n",
    "else:\n",
    "    printStamp(\"Reading pickled genotype\")\n",
    "    with open(config.p_pickfile_dev, 'rb') as input:\n",
    "        pickled_oxf = pickle.load(input)\n",
    "\n",
    "    printStamp(\"Done reading\")\n",
    "\n",
    "    p_genotype = np.array(pickled_oxf.dosage)\n",
    "    p_samplenames = pickled_oxf.samplenames\n",
    "    p_snps = pickled_oxf.snps_info\n",
    "    p_nsample = len(pickled_oxf.samplenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p = config.parameters[0]\n",
    "\n",
    "prior = p[0]\n",
    "params = p[1]\n",
    "hyperpriors = []\n",
    "hyperparams = p[3]\n",
    "run_description = p[4]\n",
    "cutoff = p[5]\n",
    "usedist = p[6]\n",
    "usefeat = p[7]\n",
    "\n",
    "\n",
    "print(p)\n",
    "\n",
    "\n",
    "model_dir = \"{:s}_{:s}_{:s}_{:s}_{:.3f}_{:.3f}_{:.3f}_{:.3f}_{:.3f}\".format(prior, cutoff, usedist, usefeat, params[0], params[1], params[2], params[3], params[4])\n",
    "outdir = \"/home/franco/soedinglab/dev_gxpred_models/\"\n",
    "modelpath = os.path.join(outdir, \"z\"+str(config.zmax), config.run_description, model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "outfileprefix = os.path.join(modelpath,\"pred_chr\"+str(config.chrom))\n",
    "\n",
    "printStamp(\"Predicting for \"+modelpath)\n",
    "# Write predictions for each model\n",
    "p_model = ReadModel(modelpath, config.chrom)\n",
    "p_genes = p_model.genes\n",
    "gx = list()\n",
    "for gene in p_genes:\n",
    "\n",
    "    p_model.read_gene(gene)\n",
    "    p_model_snps = p_model.snps\n",
    "    p_model_zstates = p_model.zstates\n",
    "\n",
    "    x = gtutils.prediction_variables(p_snps, p_model_snps, p_genotype)\n",
    "    x = gtutils.normalize(p_model_snps, x)\n",
    "\n",
    "    ypred = np.zeros(p_nsample)\n",
    "    for z in p_model_zstates:\n",
    "        ypred += z.prob * np.dot(x.T, z.exp)\n",
    "\n",
    "    gx.append(GeneExpressionArray(geneid = gene.ensembl_id, expr_arr = ypred))\n",
    "\n",
    "\n",
    "# Write output\n",
    "printStamp(\"Done predicting for \"+modelpath)\n",
    "mfunc.write_gcta_phenotype(outfileprefix, p_samplenames, gx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import os\n",
    "from iotools import readgtf\n",
    "from iotools.readrpkm import ReadRPKM\n",
    "from iotools.readPrediction import ReadPrediction\n",
    "from scipy.stats import pearsonr\n",
    "from utils.helper_functions import write_r2_dataframe, get_common_elements, pearson_corr_rowwise\n",
    "import math\n",
    "import pickle\n",
    "from utils.printstamp import printStamp\n",
    "\n",
    "import config_annots as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load reference dataset Gene Expression\n",
    "reference_rpkm = ReadRPKM(config.reference_expdatapath, config.predicting_dataset)\n",
    "reference_expression = reference_rpkm.expression\n",
    "reference_expr_donors = reference_rpkm.donor_ids\n",
    "reference_gene_names = reference_rpkm.gene_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the selected_gene_ids with high RÂ² values as targets, only those in the selected chrom will appear\n",
    "# genelistfile = \"genes4testing_highr2\"\n",
    "genelistfile = \"genes4testing_high_and_low_r2_0.001\"\n",
    "selected_gene_ids = load_target_genes(genelistfile, gene_info, config.chrom)\n",
    "target_genelist = [g.split(\".\")[0] for g in selected_gene_ids]\n",
    "target_donors = reference_expr_donors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Predixcan assessment ###\n",
    "\n",
    "if not os.path.exists(config.predixcan_pickfile_dev):\n",
    "    predixcanpred = ReadPrediction(config.pxpred_predpath, config.reference_samplepath, \"predixcan\", trim=True)\n",
    "\n",
    "    if len(predixcanpred.gene_names) > 0:\n",
    "        printStamp(\"Dumping Predixcan prediction\")\n",
    "        with open(config.predixcan_pickfile_dev, 'wb') as output:\n",
    "            pickle.dump(predixcanpred, output, pickle.HIGHEST_PROTOCOL)\n",
    "    else:\n",
    "        raise(\"No prediction data found\")\n",
    "else:\n",
    "    printStamp(\"Reading pickled Predixcan prediction\")\n",
    "    with open(config.predixcan_pickfile_dev, 'rb') as input:\n",
    "        predixcanpred = pickle.load(input)\n",
    "\n",
    "# filter predixcan predictions with only those in gxpred\n",
    "predixcanpred.sort_by_gene(target_genelist)\n",
    "predixcanpred.sort_by_samples(target_donors, use_prev=True)\n",
    "\n",
    "sorted_expr_donors, ix_samples = get_common_elements(reference_expr_donors, predixcanpred.sorted_samples)\n",
    "sorted_gene_names, ix_genes = get_common_elements(reference_gene_names, predixcanpred.sorted_gene_names)\n",
    "sorted_expression = reference_expression[ix_genes,:][:, ix_samples].T\n",
    "\n",
    "predixcan_r = pearson_corr_rowwise(predixcanpred.sorted_expr_mat.T, sorted_expression.T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "### GXpred assessment ###\n",
    "\n",
    "print(modelpath)\n",
    "\n",
    "gxpred_predpath = os.path.join(modelpath)\n",
    "gxpred = ReadPrediction(gxpred_predpath, config.reference_samplepath, \"gxpred\", trim=True)\n",
    "\n",
    "# filter gxpred predicted values\n",
    "gxpred.sort_by_gene(target_genelist)\n",
    "gxpred.sort_by_samples(target_donors, use_prev=True)\n",
    "\n",
    "\n",
    "# Filter and sort the reference expression values\n",
    "# Cardiogenics variables\n",
    "# expression\n",
    "# expr_donors\n",
    "# gene_names\n",
    "\n",
    "sorted_expr_donors, ix_samples = get_common_elements(reference_expr_donors, gxpred.sorted_samples)\n",
    "sorted_gene_names, ix_genes = get_common_elements(reference_gene_names, gxpred.sorted_gene_names)\n",
    "sorted_expression = reference_expression[ix_genes,:][:, ix_samples].T\n",
    "\n",
    "# Calculate Pearson correlation\n",
    "gxpred_r = pearson_corr_rowwise(gxpred.sorted_expr_mat.T, sorted_expression.T)\n",
    "\n",
    "print(gxpred.sorted_gene_names)\n",
    "print(gxpred_r**2)\n",
    "print(predixcan_r**2)\n",
    "\n",
    "\n",
    "# Write to table with predictions for given genes\n",
    "# predtabledir = os.path.join(home, \"gxpred\",\"devtools\", \"all_predictions.txt\")\n",
    "# new_write_predicted_r2(predtabledir, prior, params, gxpred_r, predixcan_r, gxpred.sorted_gene_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "write_r2_dataframe(modelpath, config.chrom, \"predixcan\", predixcan_r, predixcanpred, overwrite=True)\n",
    "write_r2_dataframe(modelpath, config.chrom, \"gxpred-bslmm\", gxpred_r, gxpred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
